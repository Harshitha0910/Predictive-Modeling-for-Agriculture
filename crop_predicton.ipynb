{"cells":[{"cell_type":"code","execution_count":1,"id":"2541ed11-ff78-4530-a4a3-84e9eb93e179","metadata":{"executionCancelledAt":null,"executionTime":72463,"lastExecutedAt":1719062750078,"lastExecutedByKernel":"755106da-b08d-4ca0-9a25-0636c00e2a32","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import pandas as pd\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score, balanced_accuracy_score\n\n# Load the dataset\ncrops = pd.read_csv(\"soil_measures.csv\")\n\n# Check for missing values\nmissing_values = crops.isnull().sum()\nprint(\"Missing values:\\n\", missing_values)\n\n# Get unique crop types\nunique_crop_types = crops['crop'].unique()\nprint(\"Unique crop types:\\n\", unique_crop_types)\n\n# Define the target variable\ntarget = 'crop'\n\n# Split the data into features and target variable\nX = crops.drop(columns=[target])  # Features\ny = crops[target]                 # Target variable\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# Define the features to be used in the model\nfeatures = [\"N\", \"P\", \"K\", \"ph\"]\n\n# Create an empty dictionary to store predictive performance of each feature\nfeatures_dict = {}\n\n# Loop through each feature to build a model\nfor feature in features:\n    # Isolate the current feature for model training\n    X_train_feature = X_train[[feature]]\n    X_test_feature = X_test[[feature]]\n\n    # Create a logistic regression model set for multinomial multi-class classification\n    log_reg = LogisticRegression(multi_class=\"multinomial\", max_iter=500)  # Increase max_iter if needed\n\n    # Fit the model on the training data using only the selected feature\n    log_reg.fit(X_train_feature, y_train)\n\n    # Predict the target values using the test set\n    y_pred = log_reg.predict(X_test_feature)\n\n    # Calculate the F1 score and balanced accuracy score\n    f1 = f1_score(y_test, y_pred, average=\"weighted\")\n    balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n\n    # Store the results in the dictionary\n    features_dict[feature] = {\"F1 Score\": f1, \"Balanced Accuracy\": balanced_accuracy}\n\n# Print the performance for each feature\nfor feature, scores in features_dict.items():\n    print(f\"F1-score for {feature}: {scores['F1 Score']:.4f}\")\n    print(f\"Balanced Accuracy for {feature}: {scores['Balanced Accuracy']:.4f}\")\n\n# Define which metric to compare, e.g., \"F1 Score\"\ncomparison_metric = \"F1 Score\"\n\n# Use a lambda function to fetch the specific metric from nested dictionaries for comparison\nbest_feature = max(features_dict, key=lambda x: features_dict[x][comparison_metric])\nbest_score = features_dict[best_feature][comparison_metric]\n\n# Create a dictionary to store the best predictive feature and its score\nbest_predictive_feature = {best_feature: best_score}\n\n# Print the best predictive feature and its score\nprint(\"Best Predictive Feature:\", best_predictive_feature)\n\n# Train the model using the entire dataset for the best feature\nbest_feature_model = LogisticRegression(multi_class=\"multinomial\", max_iter=500)\nbest_feature_model.fit(crops[[best_feature]], crops[target])\n\n# Function to predict crop type based on input values\ndef predict_crop(N, P, K, ph):\n    input_data = pd.DataFrame([[N, P, K, ph]], columns=[\"N\", \"P\", \"K\", \"ph\"])\n    prediction = best_feature_model.predict(input_data[[best_feature]])\n    return prediction[0]\n\n# Example usage\nN = float(input(\"Enter value for N: \"))\nP = float(input(\"Enter value for P: \"))\nK = float(input(\"Enter value for K: \"))\nph = float(input(\"Enter value for ph: \"))\n\npredicted_crop = predict_crop(N, P, K, ph)\nprint(\"Predicted crop type:\", predicted_crop)\n","outputsMetadata":{"0":{"height":563,"type":"stream"}}},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'sklearn'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m f1_score, balanced_accuracy_score\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"]}],"source":["import pandas as pd\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import f1_score, balanced_accuracy_score\n","\n","# Load the dataset\n","crops = pd.read_csv(\"soil_measures.csv\")\n","\n","# Check for missing values\n","missing_values = crops.isnull().sum()\n","print(\"Missing values:\\n\", missing_values)\n","\n","# Get unique crop types\n","unique_crop_types = crops['crop'].unique()\n","print(\"Unique crop types:\\n\", unique_crop_types)\n","\n","# Define the target variable\n","target = 'crop'\n","\n","# Split the data into features and target variable\n","X = crops.drop(columns=[target])  # Features\n","y = crops[target]                 # Target variable\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n","\n","# Define the features to be used in the model\n","features = [\"N\", \"P\", \"K\", \"ph\"]\n","\n","# Create an empty dictionary to store predictive performance of each feature\n","features_dict = {}\n","\n","# Loop through each feature to build a model\n","for feature in features:\n","    # Isolate the current feature for model training\n","    X_train_feature = X_train[[feature]]\n","    X_test_feature = X_test[[feature]]\n","\n","    # Create a logistic regression model set for multinomial multi-class classification\n","    log_reg = LogisticRegression(multi_class=\"multinomial\", max_iter=500)  # Increase max_iter if needed\n","\n","    # Fit the model on the training data using only the selected feature\n","    log_reg.fit(X_train_feature, y_train)\n","\n","    # Predict the target values using the test set\n","    y_pred = log_reg.predict(X_test_feature)\n","\n","    # Calculate the F1 score and balanced accuracy score\n","    f1 = f1_score(y_test, y_pred, average=\"weighted\")\n","    balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n","\n","    # Store the results in the dictionary\n","    features_dict[feature] = {\"F1 Score\": f1, \"Balanced Accuracy\": balanced_accuracy}\n","\n","# Print the performance for each feature\n","for feature, scores in features_dict.items():\n","    print(f\"F1-score for {feature}: {scores['F1 Score']:.4f}\")\n","    print(f\"Balanced Accuracy for {feature}: {scores['Balanced Accuracy']:.4f}\")\n","\n","# Define which metric to compare, e.g., \"F1 Score\"\n","comparison_metric = \"F1 Score\"\n","\n","# Use a lambda function to fetch the specific metric from nested dictionaries for comparison\n","best_feature = max(features_dict, key=lambda x: features_dict[x][comparison_metric])\n","best_score = features_dict[best_feature][comparison_metric]\n","\n","# Create a dictionary to store the best predictive feature and its score\n","best_predictive_feature = {best_feature: best_score}\n","\n","# Print the best predictive feature and its score\n","print(\"Best Predictive Feature:\", best_predictive_feature)\n","\n","# Train the model using the entire dataset for the best feature\n","best_feature_model = LogisticRegression(multi_class=\"multinomial\", max_iter=500)\n","best_feature_model.fit(crops[[best_feature]], crops[target])\n","\n","# Function to predict crop type based on input values\n","def predict_crop(N, P, K, ph):\n","    input_data = pd.DataFrame([[N, P, K, ph]], columns=[\"N\", \"P\", \"K\", \"ph\"])\n","    prediction = best_feature_model.predict(input_data[[best_feature]])\n","    return prediction[0]\n","\n","# Example usage\n","N = float(input(\"Enter value for N: \"))\n","P = float(input(\"Enter value for P: \"))\n","K = float(input(\"Enter value for K: \"))\n","ph = float(input(\"Enter value for ph: \"))\n","\n","predicted_crop = predict_crop(N, P, K, ph)\n","print(\"Predicted crop type:\", predicted_crop)\n"]}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"}},"nbformat":4,"nbformat_minor":5}
